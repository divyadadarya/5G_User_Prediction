{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from scipy.stats import pearsonr, kendalltau, spearmanr\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "output = pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['call_days', 're_call10', 'short_call10', 'long_call10', 'bank_cnt', 'active_days01']\n",
    "target = ['is_5g']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = pd.DataFrame(columns = ['Pearson Correlation', 'Kendall Correlation', 'Spearman Correlation'], \n",
    "                           index = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in features:\n",
    "    corr_pearson, _ = pearsonr(train[x], train[target])\n",
    "    corr_kendall, _ = kendalltau(train[x], train[target])\n",
    "    corr_spearman, _ = spearmanr(train[x], train[target])\n",
    "    \n",
    "    correlation.loc[x] = [corr_pearson[0], corr_kendall, corr_spearman]\n",
    "    \n",
    "correlation.to_csv('temp2_correlations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = output[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function of Interactive Confusion Matrix\n",
    "def cm_plotter(y_test, y_pred):\n",
    "    cols = list(y_test.unique())\n",
    "    z = confusion_matrix(y_test, y_pred)\n",
    "    #print(z)\n",
    "    z = z[::-1]\n",
    "    \n",
    "    #r_list SHOULD BE A . Use list() if needed.\n",
    "    x = cols\n",
    "    y = x[::-1].copy() # invert idx values of x \n",
    "    #print(type(x))\n",
    "    #print(type(y))\n",
    "    \n",
    "    z_text = [[str(y) for y in x] for x in z]\n",
    "    \n",
    "    # set up figure\n",
    "    fig = ff.create_annotated_heatmap(z, x = x, y = y, annotation_text = z_text, colorscale = 'Viridis')\n",
    "    \n",
    "    # add title\n",
    "    fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
    "                    #xaxis = dict(title = 'x'),\n",
    "                    #yaxis = dict(title = 'x')\n",
    "    )\n",
    "    \n",
    "    # add custom xaxis title\n",
    "    fig.add_annotation(dict(font = dict(color = \"black\", size = 14),\n",
    "                            x = 0.5,\n",
    "                            y = -0.15,\n",
    "                            showarrow = False,\n",
    "                            text = \"Predicted value\",\n",
    "                            xref = \"paper\",\n",
    "                            yref = \"paper\"))\n",
    "\n",
    "    # add custom yaxis title\n",
    "    fig.add_annotation(dict(font = dict(color = \"black\", size = 14),\n",
    "                            x = -0.35,\n",
    "                            y = 0.5,\n",
    "                            showarrow = False,\n",
    "                            text = \"Real value\",\n",
    "                            textangle = -90,\n",
    "                            xref = \"paper\",\n",
    "                            yref = \"paper\"))\n",
    "\n",
    "    # adjust margins to make room for yaxis title\n",
    "    fig.update_layout(margin = dict(t = 50, l = 200))\n",
    "\n",
    "    # add colorbar\n",
    "    fig['data'][0]['showscale'] = True\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classification\n",
    "classifier_random_forest = RandomForestClassifier(n_estimators = 20, criterion = 'entropy', random_state = 42, \n",
    "                                                  max_features = 'auto', max_depth = 10, min_samples_split = 6, \n",
    "                                                  min_samples_leaf = 2, bootstrap = False) \n",
    "\n",
    "classifier_random_forest.fit(X_train, np.ravel(y_train))\n",
    "y_pred_random_forest = classifier_random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest =  1.0\n",
      "Matthews correlation coefficient of Random Forest =  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "#Calculating Accuracy of Random Forest Classification\n",
    "accuracy_random_forest = accuracy_score(y_test, y_pred_random_forest)\n",
    "print(\"Accuracy of Random Forest = \", accuracy_random_forest)\n",
    "\n",
    "#Calculating MCC of Random Forest Classification\n",
    "mcc_random_forest = matthews_corrcoef(y_test, y_pred_random_forest)\n",
    "print(\"Matthews correlation coefficient of Random Forest = \", mcc_random_forest)\n",
    "\n",
    "#Confusion Matrix of Random Forest Classification\n",
    "#fig_cm_random_forest = cm_plotter(y_test, y_pred_random_forest)\n",
    "#fig_cm_random_forest.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    300000\n",
      "\n",
      "    accuracy                           1.00    300000\n",
      "   macro avg       1.00      1.00      1.00    300000\n",
      "weighted avg       1.00      1.00      1.00    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report of Random Forest Classification\n",
    "print(classification_report(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divya\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:05:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "classifier_xgb = xgb.XGBClassifier(n_estimators = 100, eta = 0.2, gamma = 100, max_depth = 3, subsample = 0.5, reg_lambda = 5, alpha = 5, \n",
    "                           colsample_bytree = 0.7, min_child_weight = 5)\n",
    "classifier_xgb.fit(X_train, np.ravel(y_train))\n",
    "y_pred_xgb = classifier_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGB =  1.0\n",
      "Matthews correlation coefficient of XGB =  0.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating Accuracy of XGBoost\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"Accuracy of XGB = \", accuracy_xgb)\n",
    "\n",
    "#Calculating MCC of XGBoost\n",
    "mcc_xgb = matthews_corrcoef(y_test, y_pred_xgb)\n",
    "print(\"Matthews correlation coefficient of XGB = \", mcc_xgb)\n",
    "\n",
    "#Confusion Matrix of XGBoost\n",
    "#fig_cm_xgb = cm_plotter(y_test, y_pred_xgb)\n",
    "#fig_cm_xgb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    300000\n",
      "\n",
      "    accuracy                           1.00    300000\n",
      "   macro avg       1.00      1.00      1.00    300000\n",
      "weighted avg       1.00      1.00      1.00    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report of XGBoost\n",
    "print(classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light_GBM\n",
    "classifier_LGBM = LGBMClassifier(n_estimators = 80, max_depth = 1, num_leaves = 10, learning_rate = 0.1, boosting_type = 'dart')\n",
    "classifier_LGBM.fit(X_train, np.ravel(y_train))\n",
    "y_pred_LGBM = classifier_LGBM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LGBM =  1.0\n",
      "Matthews correlation coefficient of LGBM =  0.0\n"
     ]
    }
   ],
   "source": [
    "#Calculating Accuracy of LGBM\n",
    "accuracy_LGBM = accuracy_score(y_test, y_pred_LGBM)\n",
    "print(\"Accuracy of LGBM = \", accuracy_LGBM)\n",
    "\n",
    "#Calculating MCC of LGBM\n",
    "mcc_LGBM = matthews_corrcoef(y_test, y_pred_LGBM)\n",
    "print(\"Matthews correlation coefficient of LGBM = \", mcc_LGBM)\n",
    "\n",
    "#Confusion Matrix of LGBM\n",
    "#fig_cm_LGBM = cm_plotter(y_test, y_pred_LGBM)\n",
    "#fig_cm_LGBM.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    300000\n",
      "\n",
      "    accuracy                           1.00    300000\n",
      "   macro avg       1.00      1.00      1.00    300000\n",
      "weighted avg       1.00      1.00      1.00    300000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report of LGBM\n",
    "print(classification_report(y_test, y_pred_LGBM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
